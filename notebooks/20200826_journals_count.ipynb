{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count journals\n",
    "\n",
    "- What are the patterns for each representative conferences?  \n",
    "- How many entries should I manually label, for some representative conferences?\n",
    "\n",
    "I submitted [an issue](https://github.com/allenai/s2orc/issues/26) to ask if the S2ORC authors plan to unify the conference names in the future releases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Economics', 'Biology', 'Geography', 'Philosophy', 'Materials Science', 'Business', 'Mathematics', 'Chemistry', 'Medicine', 'Psychology', 'Geology', 'Political Science', 'Engineering', 'Art', 'Physics', 'Computer Science', 'Environmental Science', 'Sociology', 'History'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, time\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "from utils import timed_func\n",
    "\n",
    "with open(os.path.join(\"../scripts/20200718_preprocess\", \"journals_count.json\"), \"r\") as f:\n",
    "    journals = json.loads(f.read())\n",
    "    \n",
    "export_data_dir = \"0826_data\"\n",
    "if not os.path.exists(export_data_dir):\n",
    "    os.makedirs(export_data_dir)\n",
    "    \n",
    "journals.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187903"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs = journals[\"Computer Science\"]\n",
    "len(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34534 venues contain more than 10 items\n",
      "[('None', 385185),\n",
      " ('ArXiv', 103996),\n",
      " ('IEEE Access', 29722),\n",
      " ('Acta Crystallographica Section E: Structure Reports Online', 15444),\n",
      " ('International Journal of Computer Applications', 12825),\n",
      " ('INTERSPEECH', 10952),\n",
      " ('CACM', 10238),\n",
      " ('Applied Mechanics and Materials', 9476),\n",
      " ('Bioinformatics', 9261),\n",
      " ('Multimedia Tools and Applications', 8943)]\n"
     ]
    }
   ],
   "source": [
    "# Rank the journals by num publications\n",
    "def most_popular_journals(catname, num=10, min_count=10):\n",
    "    category = journals[catname]\n",
    "    L = [(k,category[k]) for k in category if category[k]>min_count]\n",
    "    L.sort(key=lambda item: item[1], reverse=True)\n",
    "    print(\"{} venues contain more than {} items\".format(len(L), min_count))\n",
    "    pprint(L[:num])\n",
    "    \n",
    "most_popular_journals(\"Computer Science\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total articles: 4305658 (from 187903 venues)\n",
      "4131634 articles with more than 5 papers: (95.96%, from 46817 venues)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>venue</th>\n",
       "      <th>count</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>None</td>\n",
       "      <td>385185</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ArXiv</td>\n",
       "      <td>103996</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>IEEE Access</td>\n",
       "      <td>29722</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Acta Crystallographica Section E: Structure Re...</td>\n",
       "      <td>15444</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>International Journal of Computer Applications</td>\n",
       "      <td>12825</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 venue   count label\n",
       "21                                                None  385185      \n",
       "14                                               ArXiv  103996      \n",
       "164                                        IEEE Access   29722      \n",
       "99   Acta Crystallographica Section E: Structure Re...   15444      \n",
       "502     International Journal of Computer Applications   12825      "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_to_df(category, export, min_count):\n",
    "    export_dfdata = {\"venue\": [], \"count\": [], \"label\": []} \n",
    "    for name in cs:\n",
    "        export_dfdata[\"venue\"].append(name)\n",
    "        export_dfdata[\"count\"].append(category[name])\n",
    "        export_dfdata[\"label\"].append(\"\")\n",
    "    df = pd.DataFrame(export_dfdata).sort_values(by=\"count\", ascending=False)\n",
    "    total_articles = df[\"count\"].sum()\n",
    "    print (\"Total articles: {} (from {} venues)\".format(\n",
    "        total_articles, len(df)\n",
    "    ))\n",
    "    df = df[df[\"count\"] >= min_count]\n",
    "    considered_articles = df[\"count\"].sum()\n",
    "    print (\"{} articles with more than {} papers: ({:.2f}%, from {} venues)\".format(\n",
    "        considered_articles, min_count, \n",
    "        considered_articles / total_articles * 100, len(df)\n",
    "    ))\n",
    "    if export:\n",
    "        df.to_csv(os.path.join(export_data_dir, \"journal_counts_all.csv\"), index=False)\n",
    "    return df\n",
    "\n",
    "df = data_to_df(cs, export=True, min_count=5)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: NLP\n",
      "    Venues included: 1566\n",
      "    Paper covered: 77934 of 4131634 (1.89%)\n",
      "Category: Speech\n",
      "    Venues included: 198\n",
      "    Paper covered: 54862 of 4131634 (1.33%)\n",
      "Category: ML\n",
      "    Venues included: 765\n",
      "    Paper covered: 72083 of 4131634 (1.74%)\n",
      "Category: AI\n",
      "    Venues included: 2437\n",
      "    Paper covered: 183116 of 4131634 (4.43%)\n",
      "Category: CV\n",
      "    Venues included: 996\n",
      "    Paper covered: 132429 of 4131634 (3.21%)\n",
      "Category: Robo\n",
      "    Venues included: 1149\n",
      "    Paper covered: 125986 of 4131634 (3.05%)\n",
      "(6681, 9)\n"
     ]
    }
   ],
   "source": [
    "rules_cl = [\n",
    "    lambda name: \"EMNLP\" in name or \"empirical methods\" in name.lower(),\n",
    "    lambda name: \"ACL\" in name,\n",
    "    lambda name: \"conll\" in name.lower(),\n",
    "    lambda name: \"ling\" in name.lower(),\n",
    "    lambda name: \"language\" in name.lower(),\n",
    "    lambda name: \"LREC\" in name,\n",
    "    lambda name: \"HLT\" in name,\n",
    "    lambda name: \"IJCNLP\" in name,\n",
    "    lambda name: \"SIGDIAL\" in name,\n",
    "]\n",
    "rules_speech = [\n",
    "    lambda name: \"ICASSP\" in name,\n",
    "    lambda name: \"speech\" in name.lower(),\n",
    "    lambda name: \"SLT\" in name,\n",
    "]\n",
    "rules_ml = [\n",
    "    lambda name: \"NIPS\" in name,\n",
    "    lambda name: \"neural\" in name.lower(),\n",
    "    lambda name: \"neural network\" in name.lower(),\n",
    "    lambda name: \"ICLR\" in name,\n",
    "    lambda name: \"ICML\" in name,\n",
    "    lambda name: \"learn\" in name.lower(),\n",
    "    lambda name: \"COLT\" in name,\n",
    "]\n",
    "rules_ai = [\n",
    "    lambda name: \"AI\" in name,\n",
    "    lambda name: \"artificial\" in name.lower(),\n",
    "    lambda name: \"intelligence\" in name.lower(),\n",
    "    lambda name: \"fuzzy\" in name.lower(),\n",
    "    lambda name: \"knowledge\" in name.lower(),\n",
    "    lambda name: \"soft comp\" in name.lower(),\n",
    "    lambda name: \"neurocomp\" in name.lower(),\n",
    "]\n",
    "rules_cv = [\n",
    "    lambda name: \"CVPR\" in name,\n",
    "    lambda name: \"vision\" in name.lower(),\n",
    "    lambda name: \"pattern\" in name.lower(),\n",
    "    lambda name: \"recognition\" in name.lower(),\n",
    "    lambda name: \"image\" in name.lower(),\n",
    "    lambda name: \"ICIP\" in name,\n",
    "    lambda name: \"ECCV\" in name,\n",
    "    lambda name: \"ICCV\" in name,\n",
    "    lambda name: \"BMVC\" in name,\n",
    "]\n",
    "rules_robo = [\n",
    "    lambda name: \"robotic\" in name.lower(),\n",
    "    lambda name: \"ICRA\" in name,\n",
    "    lambda name: \"RSS\" in name,\n",
    "    lambda name: \"automat\" in name.lower(),\n",
    "]\n",
    "        \n",
    "def find_AI_venues(df):\n",
    "    all_rules = {\n",
    "        \"NLP\": rules_cl, \"Speech\": rules_speech, \"ML\": rules_ml, \"AI\": rules_ai, \"CV\": rules_cv, \"Robo\": rules_robo\n",
    "    }\n",
    "    for rulename in all_rules:\n",
    "        df[rulename] = np.array([False] * len(df))\n",
    "        rules = all_rules[rulename]\n",
    "        for rule in rules:\n",
    "            df[rulename] = np.logical_or(\n",
    "                df[rulename].values, \n",
    "                np.array([rule(name) for name in df[\"venue\"]])\n",
    "            )\n",
    "        print (f\"Category: {rulename}\")\n",
    "        df_cat = df[df[rulename]==True]\n",
    "        print (\"    Venues included: {}\".format(len(df_cat)))\n",
    "        paper_covered = df_cat[\"count\"].sum()\n",
    "        total_paper = df[\"count\"].sum()\n",
    "        print(\"    Paper covered: {} of {} ({:.2f}%)\".format(\n",
    "            paper_covered, total_paper, paper_covered / total_paper * 100))\n",
    "        \n",
    "    df_ai = df[df[\"NLP\"] | df[\"Speech\"] | df[\"ML\"] | df[\"AI\"] | df[\"CV\"] | df[\"Robo\"]]\n",
    "    return df_ai\n",
    "\n",
    "df_ai = find_AI_venues(df)\n",
    "print(df_ai.shape)\n",
    "df_ai.to_csv(os.path.join(export_data_dir, \"df_ai.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total papers covered: 614874\n"
     ]
    }
   ],
   "source": [
    "print (\"Total papers covered: {}\".format(df_ai[\"count\"].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
